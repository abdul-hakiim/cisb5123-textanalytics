{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1657ee89",
   "metadata": {
    "id": "1657ee89"
   },
   "source": [
    "# CISB5123 Text Analytics\n",
    "## Lab Assignment 1\n",
    "\n",
    "Group pair:\n",
    "1. Name: Abdul Hakiim bin Ahmad Rosli (SW01081337)\n",
    "2. Name: Muhammad Bazly bin Burhan (SW01081224)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5de7e118",
   "metadata": {
    "id": "5de7e118"
   },
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import requests\n",
    "import csv\n",
    "import json\n",
    "import re\n",
    "import pandas as pd\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7cdac48b",
   "metadata": {
    "id": "7cdac48b"
   },
   "outputs": [],
   "source": [
    "# Define the product URL\n",
    "url = 'https://shopee.com.my/Philips-1.8L-Bakuhanseki-Smart-Rice-Cooker-HD4515-(HD4515-67)-i.10513631.8708423968?sp_atk=201547bd-4008-4c4b-a562-50d57707af37&xptdk=201547bd-4008-4c4b-a562-50d57707af37&is_from_login=true'\n",
    "\n",
    "# Function to look for specific pattern in the URL\n",
    "r = re.search(r'i\\.(\\d+)\\.(\\d+)', url)\n",
    "\n",
    "# If the pattern is found, extract the data\n",
    "if r:\n",
    "    shop_id, item_id = r.group(1), r.group(2)\n",
    "else:\n",
    "    print(\"Invalid URL\")\n",
    "    exit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2b5c67ff",
   "metadata": {
    "id": "2b5c67ff"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty list to store the review\n",
    "review_list = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "918068b2",
   "metadata": {
    "id": "918068b2"
   },
   "outputs": [],
   "source": [
    "# Initialize offset to 0 which used to paginate through the reviews\n",
    "offset = 0\n",
    "\n",
    "# Initialize a counter for the number of pages\n",
    "page_count = 1\n",
    "\n",
    "# Enters while loop to fetch reviews in batches of 20 (as indicated by the 'limit=20' query parameter in the request URL)\n",
    "while True:\n",
    "    ratings_url = f'https://shopee.com.my/api/v2/item/get_ratings?filter=0&flag=1&itemid={item_id}&limit=20&offset={offset}&shopid={shop_id}&type=0'\n",
    "    data = requests.get(ratings_url).json()\n",
    "\n",
    "    # Iterate through each rating and append it to the data list\n",
    "    for rating in data['data']['ratings']:\n",
    "        author_username = rating['author_username']\n",
    "\n",
    "        # Convert Unix timestamp to readable date and time\n",
    "        timestamp = rating['ctime']\n",
    "        readable_time = datetime.fromtimestamp(timestamp).strftime('%Y-%m-%d %H:%M:%S')\n",
    "\n",
    "        comment = rating['comment']\n",
    "\n",
    "        # Append a dictionary for each rating to the review_list\n",
    "        review_list.append({\n",
    "            'Author Username': author_username,\n",
    "            'Date': readable_time,\n",
    "            'Comment': comment\n",
    "        })\n",
    "\n",
    "    # Check if the number of reviews fetched less than 20,\n",
    "    # or page_count already reach 5 pages. If so, then break\n",
    "    # the loop\n",
    "    if len(data['data']['ratings']) < 20 or page_count >= 5:\n",
    "        break\n",
    "\n",
    "    # Increase the page count\n",
    "    page_count += 1\n",
    "\n",
    "    # Increase offset by 20 to fetch the next page\n",
    "    offset += 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "fblAmEMtU1ch",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "fblAmEMtU1ch",
    "outputId": "31ddbf08-6b4f-4043-c419-3f3bb142d500"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "All reviews have been saved to shopee.csv\n"
     ]
    }
   ],
   "source": [
    "# Save the review to a CSV file\n",
    "with open('shopee.csv', 'w', encoding='utf-8', newline='') as csvfile:\n",
    "    fieldnames = ['Author Username', 'Date', 'Comment']\n",
    "    writer = csv.DictWriter(csvfile, fieldnames=fieldnames)\n",
    "\n",
    "    # Write headers\n",
    "    writer.writeheader()\n",
    "\n",
    "    # Write quotes\n",
    "    for review in review_list:\n",
    "        writer.writerow(review)\n",
    "\n",
    "# Other method to convert review_list to CSV file\n",
    "# using pandas DataFrame\n",
    "# df = pd.DataFrame(review_list)\n",
    "\n",
    "# Save the DataFrame to a CSV file\n",
    "# df.to_csv('shopee.csv', index=False)\n",
    "\n",
    "# Once done print status message\n",
    "print(\"All reviews have been saved to shopee.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4197d6",
   "metadata": {
    "id": "cb4197d6"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
